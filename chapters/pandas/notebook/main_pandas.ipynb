{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73a339f2",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- dom:TITLE: Organizing data: pandas -->\n",
    "# Organizing data: pandas\n",
    "**Aksel Hiorth**\n",
    "University of Stavanger\n",
    "\n",
    "Date: **Aug 19, 2022**\n",
    "\n",
    "<!-- Common Mako variables and functions -->\n",
    "\n",
    "# What is Pandas?\n",
    "Pandas is a Python package that among many things are used to handle data, and perform operations on groups of data. It is built on top of Numpy, which makes it easy to perform vectorized operations. Pandas is written by Wes McKinney, and one of it objectives is according to the official website [ '' providing fast, flexible, and expressive data structures designed to make working with ''relational'' or ''labeled'' data both easy and intuitive. It aims to be the fundamental high-level building block for doing practical, real-world data analysis in Python''](https://pandas.pydata.org/). Pandas also has excellent functions for reading and writing excel and csv files.  An excel file is read directly into memory in what is called a `DataFrame` in Pandas. A DataFrame is a two dimensional object where data are typically stored in column or row format. Pandas has a lot of functions that can be used to calculate statistical properties of the data frame as a whole. In this chapter we will focus on basic data manipulation, stuff you might do in excel, but can be done much faster in Python and Pandas.\n",
    "\n",
    "# Creating a data frame\n",
    "In the following we will assume that you have imported pandas, like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845d7c50",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8b37f2",
   "metadata": {
    "editable": true
   },
   "source": [
    "## From empty DataFrame\n",
    "This is perhaps the most basic way of creating a DataFrame, first we create an empty DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baac2bc0",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1d0006",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Variable name.**\n",
    "\n",
    "Note that we often use `df` as a variable name for a DataFrame, this is a choice, but it is a usually a good choice as someone else reading the code could infer from a name that `df` is a DataFrame. If you need more than one DataFrame variable you could use `df1`, `df2`, etc. or even better to use a descriptive name, `df_sales_data`.\n",
    "\n",
    "\n",
    "Next, we can add columns to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d6a28e",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df['a']=[0,1,2,3]\n",
    "df['b']=[4,5,6,7]\n",
    "df['c']=['hammer','saw','rock','nail']\n",
    "print(df) # to view data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35926a7c",
   "metadata": {
    "editable": true
   },
   "source": [
    "Note that all columns needs to have the same size.\n",
    "**`pd.Series()`.**\n",
    "\n",
    "Even if we initialize the DataFrame column with a list, the command `type(df['a'])` will tell you that the column in the DataFrame are of type `pd.Series()`. Thus the fundamental objects in Pandas are of type `Series`. Series are more flexible, and it is possible to calculate `df['a']/df['b']`, whereas `[0,1,2,3]/[4,5,6,7]` is not possible.\n",
    "\n",
    "\n",
    "## From file\n",
    "Assume you have some data organized in excel or in a csv file. The csv file could just be a file with column data, they could be separated by a comma or tab\n",
    "<!-- dom:FIGURE: [fig-pandas/covid_comb.png, width=400 frac=1.0] Official Covid-19 data, and example of files (left) tab separated (right) excel file. <div id=\"fig:file\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:file\"></div>\n",
    "\n",
    "<img src=\"fig-pandas/covid_comb.png\" width=400><p style=\"font-size: 0.9em\"><i>Figure 1: Official Covid-19 data, and example of files (left) tab separated (right) excel file.</i></p>\n",
    "<!-- end figure -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd2553f7",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel('file.xlsx') # excel file\n",
    "df=pd.read_csv('file.csv',sep=',') # csv comma separated file\n",
    "df=pd.read_csv('file.csv',sep='\\t') # csv tab separated file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073fcbd3",
   "metadata": {
    "editable": true
   },
   "source": [
    "If the excel file has several sheets, you can give the sheet name directly, e.g. `df=pd.read_excel('file.xlsx',sheet_name=\"Sheet1\")`, for more information see the [documentation](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html). \n",
    "\n",
    "**Accessing files.**\n",
    "\n",
    "Accessing files from python can be painful. If excel files are open in excel, Windows will not allow a different program to access it - always remember to close the file before opening it. Sometimes we are not in the right directory, to check which directory you are in, you can always do the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "355f3f1e",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd()) # prints current working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bc98a6",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create DataFrame from dictionary\n",
    "A DataFrame can be quite easily be generated from a dictionary. A dictionary is a special data structure, where an unique key is associated with a data type (key:value pair). In this case, the key would be the title of the column, and the value would be the data in the columns. To generate the excel file in [figure 1](#fig:file), we can do (see [figure 2](#fig:pandas:cc) for the final result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cd28c32",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "a=dt.datetime(2020,2,24,23,59) # 24/2-2020 23:59\n",
    "b=dt.datetime(2020,2,7,23,59)\n",
    "my_dict={'LOCATION':7*['Afghanistan'] + 6*['Diamond Princess'], \n",
    "'TIME':[a+dt.timedelta(days=i) for i in range(7)] +\n",
    "[b+dt.timedelta(days=i) for i in range(6)],\n",
    "'ELAPSED_TIME_SINCE_OUTBREAK':[0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 5],\n",
    "'CONFIRMED':7*[1]+[61, 61, 64, 135, 135, 175],\n",
    "'DEATHS':13*[0],\n",
    "'RECOVERED': 13*[0]}\n",
    "df=pd.DataFrame(my_dict)\n",
    "print(df) # to view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9292b1d8",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- dom:FIGURE: [fig-pandas/df.png, width=400 frac=1.0] The resulting DataFrame of Covid-19 data. <div id=\"fig:pandas:cc\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:pandas:cc\"></div>\n",
    "\n",
    "<img src=\"fig-pandas/df.png\" width=400><p style=\"font-size: 0.9em\"><i>Figure 2: The resulting DataFrame of Covid-19 data.</i></p>\n",
    "<!-- end figure -->\n",
    "\n",
    "Note that all columns must have the same length to create the DataFrame. We can easily save the data frame to excel format and open it in excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8d08a29",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.to_excel('covid19.xlsx', index=False) # what happens if you put index=True?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de2df72",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Index column.**\n",
    "\n",
    "Whenever you create a DataFrame Pandas by default create an index column, it contains an integer for each row starting at zero. It can be accessed by `df.index`, and it is also possible to define another column as index column.\n",
    "\n",
    "\n",
    "\n",
    "## Manipulating DataFrames\n",
    "\n",
    "## Selecting columns\n",
    "If we want to pick out a specific column we can access it in the following ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "979e16d3",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "time=df['TIME'] # by the name, alternatively\n",
    "time=df[df.columns[1]] \n",
    "time=df.loc[:,['TIME']] # by loc[] if we use name\n",
    "time=df.iloc[:,1] # by iloc, pick column number 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf44be6",
   "metadata": {
    "editable": true
   },
   "source": [
    "The `loc[]` and `iloc[]` functions allows for list slicing, one can then pick e.g. every second element in the column by `time=df.iloc[::2,1]` etc. The difference is that `loc[]` uses the name, and `iloc[]` the index (usually an integer). \n",
    "**Special characters.**\n",
    "\n",
    "Sometimes when reading files from excel, headers may contains invisible characters like newline `\\n` or tab `\\t` or maybe Norwegian special letters that have not been read in properly. If you have problem accessing a column by name do `print(df.columns)` and check if the name matches what you would expect.\n",
    "\n",
    "\n",
    "\n",
    "## Selecting rows\n",
    "Typically you would select rows based on a criterion, the syntax in Pandas is that you enter a series containing `True` and `False` for the rows you want to pick out, e.g. to pick out all entries with Afghanistan we can do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f5ec25",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df[df['LOCATION'] == 'Afghanistan']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea8436c",
   "metadata": {
    "editable": true
   },
   "source": [
    "The innermost statement `df['LOCATION'] == 'Afghanistan'` gives a logical vector with the value `True` for the five last elements and `False` for the rest. Then we pass this to the DataFrame, and in one go the unwanted elements are removed. It is also possible to use several criteria, e.g. only extracting data after a specific time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "894a4806",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df[(df['LOCATION'] == 'Afghanistan') & (df['ELAPSED_TIME_SINCE_OUTBREAK'] > 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a1acfc",
   "metadata": {
    "editable": true
   },
   "source": [
    "Note that the parenthesis are necessary, otherwise the logical operation would fail.\n",
    "## Performing mathematical operations on DataFrames\n",
    "When performing mathematical operations on DataFrames there are at least two strategies\n",
    "* Extract columns from the DataFrame and perform mathematical operations on the columns using Numpy, leaving the original DataFrame intact\n",
    "\n",
    "* To operate directly on the data in the DataFrame using the Pandas library\n",
    "\n",
    "**Speed and performance.**\n",
    "\n",
    "Using Pandas or Numpy should in principle be equally fast. The advice is to not worry about performance before it is necessary. Use the methods you are confident with, and try to be consistent. By consistent, we mean that if you have found one way of doing a certain operation stick to that one and try not to implement many different ways of doing the same thing.\n",
    "\n",
    "\n",
    "\n",
    "We can always access the individual columns in a DataFrame by the syntax `df['column_name']`. \n",
    "### Example: mathematical operations on DataFrames\n",
    "\n",
    "1. Create a DataFrame with one column (`a`) containing ten thousand random uniformly distributed numbers between 0 and 1 (checkout [`np.random.uniform`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.uniform.html))\n",
    "\n",
    "2. Add two new columns: one which all elements of `a` is squared and one where the sine function is applied to column `a`\n",
    "\n",
    "3. Calculate the inverse of all the numbers in the DataFrame\n",
    "\n",
    "4. Make a plot of the results (i.e. `a` vs `a*a`, and `a` vs `sin(a)`)\n",
    "\n",
    "### Solution\n",
    "\n",
    "1. First we make the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "689594f3",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "N=10000\n",
    "a=np.random.uniform(0,1,size=N)\n",
    "df=pd.DataFrame() # empty DataFrame\n",
    "df['a']=a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4252c50",
   "metadata": {
    "editable": true
   },
   "source": [
    "If you like you could also try to use a dictionary. Next, we add the new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64571820",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['b']=df['a']*df['a'] # alternatively np.square(df['a'])\n",
    "df['c']=np.sin(df['a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0443f8",
   "metadata": {
    "editable": true
   },
   "source": [
    "1. The inverse of all the numbers in the DataFrame can be calculated by simply doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d12b041a",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "1/df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94f97f6",
   "metadata": {
    "editable": true
   },
   "source": [
    "Note: you can also do `df+df` and many other operations on the whole DataFrame.\n",
    "\n",
    "1. To make plots there are several possibilities. Personally, I tend most of the time to use the  [`matplotlib`](https://matplotlib.org/) library, simply because I know it quite well, but Pandas has a great deal of very simple methods you can use to generate nice plots with very few commands.\n",
    "\n",
    "**Matplotlib:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c920bd8d",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df['a'],df['b'], '*', label='$a^2$')\n",
    "plt.plot(df['a'],df['c'], '^', label='$\\sin(a)$')\n",
    "plt.legend() \n",
    "plt.grid() # make small grid lines\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7d8223",
   "metadata": {
    "editable": true
   },
   "source": [
    "**Pandas plotting:**\n",
    "First, let us try the built in plot command in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6802284e",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb211811",
   "metadata": {
    "editable": true
   },
   "source": [
    "If you compare this plot with the previous plot, you will see that Pandas plots all columns versus the index columns, which is not what we want. But, we can set `a` to be the index column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4eebbcfa",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df=df.set_index('a')\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5bd14f",
   "metadata": {
    "editable": true
   },
   "source": [
    "We can also make separate plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40cb7024",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945b6bc4",
   "metadata": {
    "editable": true
   },
   "source": [
    "or scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27ab23cd",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df=df.reset_index()\n",
    "df.plot.scatter(x='a',y='b')\n",
    "df.plot.scatter(x='a',y='c')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f31d7",
   "metadata": {
    "editable": true
   },
   "source": [
    "Note that we have to reset the index, otherwise there are no column named `a`. \n",
    "\n",
    "## Joining two DataFrames\n",
    "### Appending DataFrames\n",
    "\n",
    "The DataFrame with the Covid-19 data in the previous section could have been created from two separate DataFrames, using [`concat()`](https://pandas.pydata.org/docs/reference/api/pandas.concat.html). First, create two DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e7655a4",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "my_dict1={'LOCATION':7*['Afghanistan'], \n",
    "'TIME':[a+dt.timedelta(days=i) for i in range(7)],\n",
    "'ELAPSED_TIME_SINCE_OUTBREAK':[0, 1, 2, 3, 4, 5, 6],\n",
    "'CONFIRMED':7*[1],\n",
    "'DEATHS':7*[0],\n",
    "'RECOVERED': 7*[0]}\n",
    "my_dict2={'LOCATION':6*['Diamond Princess'], \n",
    "'TIME':[b+dt.timedelta(days=i) for i in range(6)],\n",
    "'ELAPSED_TIME_SINCE_OUTBREAK':[0, 1, 2, 3, 4, 5],\n",
    "'CONFIRMED':[61, 61, 64, 135, 135, 175],\n",
    "'DEATHS':6*[0],\n",
    "'RECOVERED': 6*[0]}\n",
    "df1=pd.DataFrame(my_dict1)\n",
    "df2=pd.DataFrame(my_dict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee912196",
   "metadata": {
    "editable": true
   },
   "source": [
    "Next, add them row wise (see [figure 3](#fig:pandas:concat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3b2a093",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df=pd.concat([df1,df2])\n",
    "print(df) # to view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7a118d",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- dom:FIGURE: [fig-pandas/concat.png, width=400 frac=1.0] The result of `concat()`. <div id=\"fig:pandas:concat\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:pandas:concat\"></div>\n",
    "\n",
    "<img src=\"fig-pandas/concat.png\" width=400><p style=\"font-size: 0.9em\"><i>Figure 3: The result of <code>concat()</code>.</i></p>\n",
    "<!-- end figure -->\n",
    "\n",
    "If you compare this DataFrame with the previous one, you will see that the index column is different. This is because when joining two DataFrames Pandas does not reset the index by default, doing `df=pd.concat([df1,df2],ignore_index=True)` resets the index. It is also possible to join DataFrames column vise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48af24b4",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pd.concat([df1,df2],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b756c8",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Merging DataFrames\n",
    "\n",
    "In the previous example we had two non overlapping DataFrames (separate countries and times). It could also be the case that some of the data was overlapping e.g. continuing with the Covid-19 data, one could assume that there was one data set from one region and one from another region in the same country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "707120b5",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "my_dict1={'LOCATION':7*['Diamond Princess'], \n",
    "'TIME':[b+dt.timedelta(days=i) for i in range(7)],\n",
    "'ELAPSED_TIME_SINCE_OUTBREAK':[0, 1, 2, 3, 4, 5, 6],\n",
    "'CONFIRMED':7*[1],\n",
    "'DEATHS':7*[0],\n",
    "'RECOVERED': 7*[0]}\n",
    "my_dict2={'LOCATION':2*['Diamond Princess'], \n",
    "'TIME':[b+dt.timedelta(days=i) for i in range(2)],\n",
    "'ELAPSED_TIME_SINCE_OUTBREAK':[0, 1],\n",
    "'CONFIRMED':[60, 60],\n",
    "'DEATHS':2*[0],\n",
    "'RECOVERED': 2*[0]}\n",
    "df1=pd.DataFrame(my_dict1)\n",
    "df2=pd.DataFrame(my_dict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b6625e",
   "metadata": {
    "editable": true
   },
   "source": [
    "If we do `pd.concat([df1,df2])` we will simply add all values after each other. What we want to do is to sum the number of confirmed, recovered and deaths for the same date. This can be done in several ways, but one way is to use [`pd.DataFrame.merge()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html).You can specify the columns to merge on, and choose `outer` which is union (all data from both frames) or `inner` which means the intersect (only data which you merge on that exists in both frames). After performing the commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4ad1621",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df1.merge(df2,on=['LOCATION','TIME'],how='outer')\n",
    "df1.merge(df2,on=['LOCATION','TIME'],how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c4ab95",
   "metadata": {
    "editable": true
   },
   "source": [
    "we get the results in [figure 4](#fig:pd:merge) \n",
    "<!-- dom:FIGURE: [fig-pandas/merge.png, width=400 frac=1.0] Merging to dataframes using `outer` (top) and `inner` (bottom). <div id=\"fig:pd:merge\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:pd:merge\"></div>\n",
    "\n",
    "<img src=\"fig-pandas/merge.png\" width=400><p style=\"font-size: 0.9em\"><i>Figure 4: Merging to dataframes using <code>outer</code> (top) and <code>inner</code> (bottom).</i></p>\n",
    "<!-- end figure -->\n",
    "\n",
    "Clearly in this case we need to choose `outer`. In the merge process pandas adds an extra subscript `_x` and `_y` on columns that contains the same header name. We also need to sum those, which can be done as follows (see [figure 5](#fig:pandas:merge3) for the final result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6a04a6a",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df=df1.merge(df2,on=['LOCATION','TIME'],how='outer')\n",
    "cols=['CONFIRMED','DEATHS', 'RECOVERED']\n",
    "for col in cols:\n",
    "    df[col]=df[[col+'_x',col+'_y']].sum(axis=1) # sum row elements\n",
    "    df=df.drop(columns=[col+'_x',col+'_y']) # remove obsolete columns\n",
    "# final clean up\n",
    "df['ELAPSED_TIME_SINCE_OUTBREAK']=df['ELAPSED_TIME_SINCE_OUTBREAK_x']\t\t\n",
    "df=df.drop(columns=['ELAPSED_TIME_SINCE_OUTBREAK_y','ELAPSED_TIME_SINCE_OUTBREAK_x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e636f5bf",
   "metadata": {
    "editable": true
   },
   "source": [
    "<!-- dom:FIGURE: [fig-pandas/merge3.png, width=400 frac=1.0] Result of outer merging and summing. <div id=\"fig:pandas:merge3\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:pandas:merge3\"></div>\n",
    "\n",
    "<img src=\"fig-pandas/merge3.png\" width=400><p style=\"font-size: 0.9em\"><i>Figure 5: Result of outer merging and summing.</i></p>\n",
    "<!-- end figure -->\n",
    "\n",
    "## Grouping and summing\n",
    "In many cases you want to perform a mathematical operation on some columns. Lets say we wanted to find the total number of confirmed, deaths and recovered cases in the full database. This can be done by `df[['CONFIRMED','DEATHS','RECOVERED']].sum()` or accessing each column individually and sum each of them e.g. `np.sum(df['CONFIRMED'])`. But, in some cases we have a big database, maybe of all the countries in the world, and we want to get the total number of cases in each country. This can be done very elegantly with the command [`pd.DataFrame.groupby()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html) (see [figure 6](#fig:pandas:group) for final result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7664c29d",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.groupby('LOCATION').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75882222",
   "metadata": {
    "editable": true
   },
   "source": [
    "What this command do is to sum all columns with the same location, and drop columns that cannot be summed.\n",
    "\n",
    "<!-- dom:FIGURE: [fig-pandas/group.png, width=400 frac=1.0] The results of `df.groupby('LOCATION').sum()`. <div id=\"fig:pandas:group\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:pandas:group\"></div>\n",
    "\n",
    "<img src=\"fig-pandas/group.png\" width=400><p style=\"font-size: 0.9em\"><i>Figure 6: The results of <code>df.groupby('LOCATION').sum()</code>.</i></p>\n",
    "<!-- end figure -->\n",
    "\n",
    "## Simple statistics in Pandas\n",
    "At the end it is worth mentioning the built in methods `pd.DataFrame.mean`, `pd.DataFrame.median`, `pd.DataFrame.std` which calculates the mean, median and standard deviation on the columns in the DataFrame where it make sense (i.e. avoid strings and dates). To get all these values in one go (and a few more) on can also use `pd.DataFrame.describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f302cb1",
   "metadata": {
    "collapsed": false,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2365a48c",
   "metadata": {
    "editable": true
   },
   "source": [
    "The output is shown in [figure 7](#fig:pandas:desc)\n",
    "<!-- dom:FIGURE: [fig-pandas/describe.png, width=400 frac=1.0] Output from the describe command. <div id=\"fig:pandas:desc\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"fig:pandas:desc\"></div>\n",
    "\n",
    "<img src=\"fig-pandas/describe.png\" width=400><p style=\"font-size: 0.9em\"><i>Figure 7: Output from the describe command.</i></p>\n",
    "<!-- end figure -->\n",
    "\n",
    "# Bibliography"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
